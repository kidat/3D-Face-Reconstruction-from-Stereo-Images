{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf455740",
   "metadata": {},
   "source": [
    "### 3D Face Reconstruction without Extrinsic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce5d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good matches found: 11865\n",
      "Reconstructed and saved 10007 high-quality 3D points.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import open3d as o3d\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def fast_depth_filter(points):\n",
    "    valid = np.empty(len(points), dtype=np.bool_)\n",
    "    for i in prange(len(points)):\n",
    "        z = points[i, 2]\n",
    "        valid[i] = 0.2 < z < 50.0\n",
    "    return valid\n",
    "\n",
    "def get_colors(img, points_2d):\n",
    "    h, w = img.shape[:2]\n",
    "    x = np.clip(points_2d[:, 0].round(), 0, w - 1).astype(int)\n",
    "    y = np.clip(points_2d[:, 1].round(), 0, h - 1).astype(int)\n",
    "    return img[y, x][:, None] / 255.0  # Grayscale to single-channel float\n",
    "\n",
    "def optimized_3d_reconstruction():\n",
    "    # Load stereo grayscale images\n",
    "    img_left = cv.imread(\"5/Camera_Left.png\", cv.IMREAD_GRAYSCALE)\n",
    "    img_right = cv.imread(\"5/Camera_Front.png\", cv.IMREAD_GRAYSCALE)\n",
    "    if img_left is None or img_right is None:\n",
    "        raise FileNotFoundError(\"Stereo images not found\")\n",
    "\n",
    "    # Intrinsic camera matrix\n",
    "    K = np.array([[2666.67, 0, 960.0], [0, 2250.0, 540.0], [0, 0, 1]])\n",
    "\n",
    "    # Feature detection\n",
    "    sift = cv.SIFT_create(nfeatures=500000, contrastThreshold=0.002, edgeThreshold=10, nOctaveLayers=4, sigma=1.2)\n",
    "    kpL, desL = sift.detectAndCompute(img_left, None)\n",
    "    kpR, desR = sift.detectAndCompute(img_right, None)\n",
    "\n",
    "    # Matching with Lowe's ratio test\n",
    "    bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(desL, desR, k=2)\n",
    "    good = [m for m, n in matches if m.distance < 0.9 * n.distance]\n",
    "    print(f\"Good matches found: {len(good)}\")\n",
    "    if len(good) < 2000:\n",
    "        raise ValueError(\"Insufficient good matches\")\n",
    "\n",
    "    # Extract matched points\n",
    "    ptsL = np.float32([kpL[m.queryIdx].pt for m in good])\n",
    "    ptsR = np.float32([kpR[m.trainIdx].pt for m in good])\n",
    "\n",
    "    # Estimate essential matrix and camera pose\n",
    "    E, mask = cv.findEssentialMat(ptsL, ptsR, K, method=cv.RANSAC, prob=0.999, threshold=1.0, maxIters=2000)\n",
    "    if E is None or mask.sum() < 500:\n",
    "        raise ValueError(\"Pose estimation failed\")\n",
    "    _, R, t, mask_pose = cv.recoverPose(E, ptsL, ptsR, K, mask=mask)\n",
    "\n",
    "    # Filter inliers\n",
    "    mask_final = mask.ravel() == 1\n",
    "    ptsL, ptsR = ptsL[mask_final], ptsR[mask_final]\n",
    "\n",
    "    # Triangulate 3D points\n",
    "    P0 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
    "    P1 = K @ np.hstack([R, t])\n",
    "    pts4d = cv.triangulatePoints(P0, P1, ptsL.T, ptsR.T)\n",
    "    points3d = (pts4d[:3] / pts4d[3]).T\n",
    "\n",
    "    # Depth filter\n",
    "    valid_mask = fast_depth_filter(points3d)\n",
    "    points3d = points3d[valid_mask]\n",
    "    ptsL_valid = ptsL[valid_mask]\n",
    "\n",
    "    # Use image color (grayscale) from left image\n",
    "    colors = get_colors(img_left, ptsL_valid)\n",
    "    colors = np.repeat(colors, 3, axis=1)  # Convert to RGB-like shape\n",
    "\n",
    "    # Build and clean point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points3d)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    # pcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "    pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=3.0)\n",
    "\n",
    "    # Save and report\n",
    "    o3d.io.write_point_cloud(\"Reconstruction_pose.ply\", pcd, write_ascii=False, compressed=True)\n",
    "    print(f\"Reconstructed and saved {len(pcd.points)} high-quality 3D points.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimized_3d_reconstruction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ee0f2",
   "metadata": {},
   "source": [
    "### Add Texiture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435168ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Good matches found: 15950\n",
      "Reconstructed and saved 12465 high-quality 3D points.\n",
      "Generating mesh using Poisson reconstruction...\n",
      "Mesh saved with texture: 38350 vertices, 76363 faces.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import open3d as o3d\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def fast_depth_filter(points):\n",
    "    valid = np.empty(len(points), dtype=np.bool_)\n",
    "    for i in prange(len(points)):\n",
    "        z = points[i, 2]\n",
    "        valid[i] = 0.05 < z < 100.0\n",
    "    return valid\n",
    "\n",
    "def get_colors(img, points_2d):\n",
    "    h, w = img.shape[:2]\n",
    "    x = np.clip(points_2d[:, 0].round(), 0, w - 1).astype(int)\n",
    "    y = np.clip(points_2d[:, 1].round(), 0, h - 1).astype(int)\n",
    "    return img[y, x][:, None] / 255.0  # Grayscale to single-channel float\n",
    "\n",
    "def optimized_3d_reconstruction():\n",
    "    # Load stereo grayscale images\n",
    "    img_left = cv.imread(\"5/Camera_Left.png\", cv.IMREAD_GRAYSCALE)\n",
    "    img_right = cv.imread(\"5/Camera_Front.png\", cv.IMREAD_GRAYSCALE)\n",
    "    if img_left is None or img_right is None:\n",
    "        raise FileNotFoundError(\"Stereo images not found\")\n",
    "\n",
    "    # Intrinsic camera matrix\n",
    "    K = np.array([[2666.67, 0, 960.0], [0, 2250.0, 540.0], [0, 0, 1]])\n",
    "\n",
    "    # Feature detection\n",
    "    sift = cv.SIFT_create(nfeatures=500000, contrastThreshold=0.001, edgeThreshold=5, nOctaveLayers=4, sigma=1)\n",
    "    kpL, desL = sift.detectAndCompute(img_left, None)\n",
    "    kpR, desR = sift.detectAndCompute(img_right, None)\n",
    "\n",
    "    # Matching with Lowe's ratio test\n",
    "    bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(desL, desR, k=2)\n",
    "    good = [m for m, n in matches if m.distance < 0.9 * n.distance]\n",
    "    print(f\"Good matches found: {len(good)}\")\n",
    "    if len(good) < 2000:\n",
    "        raise ValueError(\"Insufficient good matches\")\n",
    "\n",
    "    # Extract matched points\n",
    "    ptsL = np.float32([kpL[m.queryIdx].pt for m in good])\n",
    "    ptsR = np.float32([kpR[m.trainIdx].pt for m in good])\n",
    "\n",
    "    # Estimate essential matrix and camera pose\n",
    "    E, mask = cv.findEssentialMat(ptsL, ptsR, K, method=cv.RANSAC, prob=0.999, threshold=0.5, maxIters=5000)\n",
    "    if E is None or mask.sum() < 500:\n",
    "        raise ValueError(\"Pose estimation failed\")\n",
    "    _, R, t, mask_pose = cv.recoverPose(E, ptsL, ptsR, K, mask=mask)\n",
    "\n",
    "    # Filter inliers\n",
    "    mask_final = mask.ravel() == 1\n",
    "    ptsL, ptsR = ptsL[mask_final], ptsR[mask_final]\n",
    "\n",
    "    # Triangulate 3D points\n",
    "    P0 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
    "    P1 = K @ np.hstack([R, t])\n",
    "    pts4d = cv.triangulatePoints(P0, P1, ptsL.T, ptsR.T)\n",
    "    points3d = (pts4d[:3] / pts4d[3]).T\n",
    "\n",
    "    # Depth filter\n",
    "    valid_mask = fast_depth_filter(points3d)\n",
    "    points3d = points3d[valid_mask]\n",
    "    ptsL_valid = ptsL[valid_mask]\n",
    "\n",
    "    # Use image color (grayscale) from left image\n",
    "    colors = get_colors(img_left, ptsL_valid)\n",
    "    colors = np.repeat(colors, 3, axis=1)  # Convert to RGB-like shape\n",
    "\n",
    "    # Build and clean point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points3d)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "   # pcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "    #pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=5, std_ratio=3.0)\n",
    "\n",
    "    # Save and report\n",
    "    o3d.io.write_point_cloud(\"reconstruction_refined.ply\", pcd, write_ascii=False, compressed=True)\n",
    "    print(f\"Reconstructed and saved {len(pcd.points)} high-quality 3D points.\")\n",
    "\n",
    "\n",
    "    # === Step 1: Use RGB image for real color ===\n",
    "    img_left_rgb = cv.imread(\"5/Camera_Left.png\", cv.IMREAD_COLOR)\n",
    "    if img_left_rgb is None:\n",
    "        raise FileNotFoundError(\"Left RGB image not found\")\n",
    "    img_left_rgb = cv.cvtColor(img_left_rgb, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    def get_rgb_colors(img_color, points_2d):\n",
    "        h, w = img_color.shape[:2]\n",
    "        x = np.clip(points_2d[:, 0].round(), 0, w - 1).astype(int)\n",
    "        y = np.clip(points_2d[:, 1].round(), 0, h - 1).astype(int)\n",
    "        return img_color[y, x] / 255.0\n",
    "\n",
    "    colors = get_rgb_colors(img_left_rgb, ptsL_valid)\n",
    "\n",
    "    # === Step 2: Build point cloud with real color ===\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points3d)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # === Step 3: Clean point cloud ===\n",
    "    pcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.01, max_nn=30))\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=20)\n",
    "    pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=50, std_ratio=1.0)\n",
    "\n",
    "    # === Step 4: Create mesh from point cloud ===\n",
    "    print(\"Generating mesh using Poisson reconstruction...\")\n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=13)\n",
    "    mesh.compute_vertex_normals()\n",
    "\n",
    "    # === Step 5: Crop mesh to remove floating artifacts ===\n",
    "    bbox = pcd.get_axis_aligned_bounding_box()\n",
    "    mesh = mesh.crop(bbox)\n",
    "\n",
    "    # === Step 6: Color vertices using image ===\n",
    "    verts = np.asarray(mesh.vertices)\n",
    "    verts_proj = (K @ verts.T).T\n",
    "    verts_proj = verts_proj[:, :2] / verts_proj[:, 2:3]  # Normalize to pixel coords\n",
    "\n",
    "    mesh_colors = get_rgb_colors(img_left_rgb, verts_proj)\n",
    "    mesh.vertex_colors = o3d.utility.Vector3dVector(mesh_colors)\n",
    "\n",
    "    # === Step 7: Save final mesh ===\n",
    "    o3d.io.write_triangle_mesh(\"textured_mesh_pose.ply\", mesh, write_ascii=False, compressed=True)\n",
    "    print(f\"Mesh saved with texture: {len(mesh.vertices)} vertices, {len(mesh.triangles)} faces.\")\n",
    "if __name__ == \"__main__\":\n",
    "    optimized_3d_reconstruction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d75aa6",
   "metadata": {},
   "source": [
    "### Pose Estimation and Evaluation of Reconstructed 3D Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f181b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good matches found: 11865\n",
      "Essential Matrix Inliers: 84.5%\n",
      "Average Reprojection Error: 0.1090px\n",
      "Triangulation Angles: Min=3.69°, Mean=5.56°, Max=16.70°\n",
      "Saved point cloud with 10025 high-quality 3D points.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import open3d as o3d\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def fast_depth_filter(points):\n",
    "    valid = np.empty(len(points), dtype=np.bool_)\n",
    "    for i in prange(len(points)):\n",
    "        z = points[i, 2]\n",
    "        valid[i] = 0.2 < z < 50.0\n",
    "    return valid\n",
    "\n",
    "def get_colors(img, points_2d):\n",
    "    h, w = img.shape[:2]\n",
    "    x = np.clip(points_2d[:, 0].round(), 0, w - 1).astype(int)\n",
    "    y = np.clip(points_2d[:, 1].round(), 0, h - 1).astype(int)\n",
    "    return img[y, x][:, None] / 255.0\n",
    "\n",
    "def compute_reprojection_error(points3d, pts2d, P):\n",
    "    points3d_hom = np.hstack((points3d, np.ones((len(points3d), 1))))\n",
    "    proj = (P @ points3d_hom.T).T\n",
    "    proj = proj[:, :2] / proj[:, 2:]\n",
    "    errors = np.linalg.norm(proj - pts2d, axis=1)\n",
    "    return np.mean(errors)\n",
    "\n",
    "def optimized_3d_reconstruction():\n",
    "    img_left = cv.imread(\"5/Camera_Left.png\", cv.IMREAD_GRAYSCALE)\n",
    "    img_right = cv.imread(\"5/Camera_Front.png\", cv.IMREAD_GRAYSCALE)\n",
    "    if img_left is None or img_right is None:\n",
    "        raise FileNotFoundError(\"Stereo images not found\")\n",
    "\n",
    "    K = np.array([[2666.67, 0, 960.0], [0, 2250.0, 540.0], [0, 0, 1]])\n",
    "\n",
    "    sift = cv.SIFT_create(nfeatures=500000, contrastThreshold=0.002, edgeThreshold=10, nOctaveLayers=4, sigma=1.2)\n",
    "    kpL, desL = sift.detectAndCompute(img_left, None)\n",
    "    kpR, desR = sift.detectAndCompute(img_right, None)\n",
    "\n",
    "    bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(desL, desR, k=2)\n",
    "    good = [m for m, n in matches if m.distance < 0.9 * n.distance]\n",
    "    print(f\"Good matches found: {len(good)}\")\n",
    "    if len(good) < 2000:\n",
    "        raise ValueError(\"Insufficient good matches\")\n",
    "\n",
    "    ptsL = np.float32([kpL[m.queryIdx].pt for m in good])\n",
    "    ptsR = np.float32([kpR[m.trainIdx].pt for m in good])\n",
    "\n",
    "    E, mask = cv.findEssentialMat(ptsL, ptsR, K, method=cv.RANSAC, prob=0.999, threshold=1.0, maxIters=2000)\n",
    "    inlier_ratio = mask.sum() / len(mask)\n",
    "    print(f\"Essential Matrix Inliers: {inlier_ratio:.1%}\")\n",
    "\n",
    "    if E is None or mask.sum() < 500:\n",
    "        raise ValueError(\"Pose estimation failed\")\n",
    "\n",
    "    _, R, t, _ = cv.recoverPose(E, ptsL, ptsR, K, mask=mask)\n",
    "\n",
    "    mask_final = mask.ravel() == 1\n",
    "    ptsL, ptsR = ptsL[mask_final], ptsR[mask_final]\n",
    "\n",
    "    P0 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
    "    P1 = K @ np.hstack([R, t])\n",
    "    pts4d = cv.triangulatePoints(P0, P1, ptsL.T, ptsR.T)\n",
    "    points3d = (pts4d[:3] / pts4d[3]).T\n",
    "\n",
    "    # Average Reprojection Error\n",
    "    err0_mean = compute_reprojection_error(points3d, ptsL, P0)\n",
    "    err1_mean = compute_reprojection_error(points3d, ptsR, P1)\n",
    "    avg_reproj_error = (err0_mean + err1_mean) / 2\n",
    "    print(f\"Average Reprojection Error: {avg_reproj_error:.4f}px\")\n",
    "\n",
    "    # Triangulation Angles\n",
    "    C0 = np.zeros(3)\n",
    "    C1 = -R.T @ t.reshape(3)\n",
    "    vec1 = points3d - C0\n",
    "    vec2 = points3d - C1\n",
    "    norms_prod = np.linalg.norm(vec1, axis=1) * np.linalg.norm(vec2, axis=1)\n",
    "    cos_angles = np.sum(vec1 * vec2, axis=1) / np.maximum(norms_prod, 1e-10)\n",
    "    angles_deg = np.degrees(np.arccos(np.clip(cos_angles, -1, 1)))\n",
    "    print(f\"Triangulation Angles: Min={np.min(angles_deg):.2f}°, Mean={np.mean(angles_deg):.2f}°, Max={np.max(angles_deg):.2f}°\")\n",
    "\n",
    "    # Depth Filter\n",
    "    valid_mask = fast_depth_filter(points3d)\n",
    "    points3d = points3d[valid_mask]\n",
    "    ptsL_valid = ptsL[valid_mask]\n",
    "\n",
    "    # Color Mapping\n",
    "    colors = get_colors(img_left, ptsL_valid)\n",
    "    colors = np.repeat(colors, 3, axis=1)\n",
    "\n",
    "    # Point Cloud Creation\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points3d)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    o3d.io.write_point_cloud(\"reconstruction_Pose.ply\", pcd, write_ascii=False, compressed=True)\n",
    "    print(f\"Saved point cloud with {len(pcd.points)} high-quality 3D points.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimized_3d_reconstruction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
