{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2531b9",
   "metadata": {},
   "source": [
    "### Uncalibrated 3D Reconstruction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97abc12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated intrinsic matrix:\n",
      "[[2.61989006e+03 0.00000000e+00 9.60000000e+02]\n",
      " [0.00000000e+00 2.61989006e+03 5.40000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Recovered rotation:\n",
      "[[ 9.96319385e-01  2.87792949e-04  8.57181488e-02]\n",
      " [-2.48207380e-04  9.99999858e-01 -4.72468027e-04]\n",
      " [-8.57182725e-02  4.49453177e-04  9.96319314e-01]]\n",
      "Translation:\n",
      "[[-0.99996403]\n",
      " [ 0.00425277]\n",
      " [-0.00733892]]\n",
      "\n",
      "====== Reconstruction Quality Summary ======\n",
      "Matches used: 3996\n",
      "Epipolar Geometry Error (Pre-Rectification): 0.0020 px\n",
      "Vertical Disparity (Post-Rectification): 0.1647 px\n",
      "Average Reprojection Error: 0.0922 px\n",
      "Point Cloud Size: 3358\n",
      "Point Cloud Density: 0.0278 m\n",
      "Depth Mean: 9.40 m\n",
      "Depth Range: 8.44 – 11.04 m\n",
      "============================================\n",
      "Saved point cloud: output_uncalibrated/reconstruction.ply\n",
      "Reconstruction complete. Results saved in output directory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import open3d as o3d\n",
    "from numba import njit, prange\n",
    "from scipy.optimize import minimize_scalar\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ----------------------\n",
    "# Utility Functions\n",
    "# ----------------------\n",
    "@njit(parallel=True)\n",
    "def fast_depth_filter(points):\n",
    "    valid = np.empty(len(points), dtype=np.bool_)\n",
    "    for i in prange(len(points)):\n",
    "        z = points[i, 2]\n",
    "        valid[i] = 0.2 < z < 50.0\n",
    "    return valid\n",
    "\n",
    "def get_colors(img, points_2d):\n",
    "    h, w = img.shape[:2]\n",
    "    x = np.clip(points_2d[:, 0].round(), 0, w - 1).astype(int)\n",
    "    y = np.clip(points_2d[:, 1].round(), 0, h - 1).astype(int)\n",
    "\n",
    "    if len(img.shape) == 2:  # Grayscale\n",
    "        colors = img[y, x]\n",
    "        return np.stack([colors, colors, colors], axis=1) / 255.0\n",
    "    else:  # Color image\n",
    "        colors = img[y, x]\n",
    "        return colors[:, ::-1] / 255.0\n",
    "\n",
    "# ----------------------\n",
    "# Evaluation Metrics\n",
    "# ----------------------\n",
    "def compute_epipolar_error(ptsL, ptsR, F):\n",
    "    ones = np.ones((len(ptsL), 1))\n",
    "    ptsL_h = np.hstack((ptsL, ones))\n",
    "    ptsR_h = np.hstack((ptsR, ones))\n",
    "    errors = np.abs(np.diag(ptsR_h @ F @ ptsL_h.T))\n",
    "    return np.mean(errors), errors\n",
    "\n",
    "def compute_point_cloud_metrics(pcd):\n",
    "    points = np.asarray(pcd.points)\n",
    "    if len(points) < 2:\n",
    "        return {\n",
    "            'mean_neighbor_distance': 0,\n",
    "            'depth_distribution': {'mean': 0, 'std': 0, 'min': 0, 'max': 0},\n",
    "            'num_points': len(points)\n",
    "        }\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=2).fit(points)\n",
    "    distances, _ = nn.kneighbors(points)\n",
    "    mean_nn_dist = np.mean(distances[:, 1])\n",
    "\n",
    "    z_values = points[:, 2]\n",
    "    depth_stats = {\n",
    "        'mean': np.mean(z_values),\n",
    "        'std': np.std(z_values),\n",
    "        'min': np.min(z_values),\n",
    "        'max': np.max(z_values)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'mean_neighbor_distance': mean_nn_dist,\n",
    "        'depth_distribution': depth_stats,\n",
    "        'num_points': len(points)\n",
    "    }\n",
    "\n",
    "# ----------------------\n",
    "# Visualization Functions\n",
    "# ----------------------\n",
    "def draw_epipolar_lines(img1_rect, img2_rect, pts1_rect, pts2_rect, output_path):\n",
    "    img1_color = cv.cvtColor(img1_rect, cv.COLOR_GRAY2BGR)\n",
    "    img2_color = cv.cvtColor(img2_rect, cv.COLOR_GRAY2BGR)\n",
    "    h, w = img1_rect.shape\n",
    "\n",
    "    num_points = min(50, len(pts1_rect))\n",
    "    if num_points == 0:\n",
    "        return\n",
    "\n",
    "    selected_indices = random.sample(range(len(pts1_rect)), num_points)\n",
    "    pts1_selected = pts1_rect[selected_indices]\n",
    "    pts2_selected = pts2_rect[selected_indices]\n",
    "\n",
    "    for i in range(len(pts1_selected)):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        pt1 = pts1_selected[i].astype(int)\n",
    "        pt2 = pts2_selected[i].astype(int)\n",
    "\n",
    "        cv.circle(img1_color, tuple(pt1), 5, (255, 255, 255), -1)\n",
    "        cv.circle(img1_color, tuple(pt1), 3, color, -1)\n",
    "        cv.circle(img2_color, tuple(pt2), 5, (255, 255, 255), -1)\n",
    "        cv.circle(img2_color, tuple(pt2), 3, color, -1)\n",
    "\n",
    "        cv.line(img1_color, (0, pt1[1]), (w-1, pt1[1]), color, 1)\n",
    "        cv.line(img2_color, (0, pt1[1]), (w-1, pt1[1]), color, 1)\n",
    "\n",
    "    combined = np.hstack([img1_color, img2_color])\n",
    "    cv.putText(combined, \"Epipolar Lines Visualization\", (10, 30), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv.imwrite(output_path, combined)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Core Reconstruction\n",
    "# ----------------------\n",
    "def estimate_intrinsics(ptsL, ptsR, img_shape):\n",
    "    F, mask = cv.findFundamentalMat(ptsL, ptsR, cv.USAC_MAGSAC, 1.0, 0.999, 50000)\n",
    "    if F is None or F.size == 0:\n",
    "        raise ValueError(\"Fundamental matrix computation failed\")\n",
    "    \n",
    "    h, w = img_shape\n",
    "    cx, cy = w / 2, h / 2\n",
    "\n",
    "    def compute_error(f):\n",
    "        K = np.array([[f, 0, cx], [0, f, cy], [0, 0, 1]])\n",
    "        E = K.T @ F @ K\n",
    "        U, S, _ = np.linalg.svd(E)\n",
    "        return (S[0] - S[1])**2 + S[2]**2\n",
    "\n",
    "    res = minimize_scalar(compute_error, bounds=(0.3*w, 3*w), method='bounded')\n",
    "    f_opt = res.x\n",
    "    return np.array([[f_opt, 0, cx], [0, f_opt, cy], [0, 0, 1]]), F\n",
    "\n",
    "def optimized_3d_reconstruction():\n",
    "    # Load images\n",
    "    img_left = cv.imread(\"5/Camera_Left.png\", cv.IMREAD_GRAYSCALE)\n",
    "    img_right = cv.imread(\"5/Camera_Front.png\", cv.IMREAD_GRAYSCALE)\n",
    "    img_left_color = cv.imread(\"5/Camera_Left.png\", cv.IMREAD_COLOR)\n",
    "    \n",
    "    if img_left is None or img_right is None:\n",
    "        raise FileNotFoundError(\"Stereo images not found\")\n",
    "    \n",
    "    os.makedirs(\"output_uncalibrated\", exist_ok=True)\n",
    "    h, w = img_left.shape\n",
    "\n",
    "    # Feature detection and matching\n",
    "    sift = cv.SIFT_create(nfeatures=100000, contrastThreshold=0.001, edgeThreshold=5)\n",
    "    kpL, desL = sift.detectAndCompute(img_left, None)\n",
    "    kpR, desR = sift.detectAndCompute(img_right, None)\n",
    "    \n",
    "    if desL is None or desR is None or len(desL) < 100 or len(desR) < 100:\n",
    "        raise ValueError(\"Insufficient features detected\")\n",
    "\n",
    "    # Feature matching with cross-check\n",
    "    bf = cv.BFMatcher(cv.NORM_L2)\n",
    "    matches1 = bf.knnMatch(desL, desR, k=2)\n",
    "    matches2 = bf.knnMatch(desR, desL, k=2)\n",
    "    \n",
    "    good1 = [m for m, n in matches1 if m.distance < 0.8 * n.distance]\n",
    "    good2 = [m for m, n in matches2 if m.distance < 0.8 * n.distance]\n",
    "    \n",
    "    reverse_mapping = {m.queryIdx: m.trainIdx for m in good2}\n",
    "    good = [m for m in good1 if m.trainIdx in reverse_mapping and reverse_mapping[m.trainIdx] == m.queryIdx]\n",
    "\n",
    "    if len(good) < 100:\n",
    "        raise ValueError(f\"Insufficient good matches: {len(good)} < 100\")\n",
    "\n",
    "    ptsL = np.float32([kpL[m.queryIdx].pt for m in good])\n",
    "    ptsR = np.float32([kpR[m.trainIdx].pt for m in good])\n",
    "\n",
    "    # Estimate intrinsics\n",
    "    try:\n",
    "        K, F = estimate_intrinsics(ptsL, ptsR, img_left.shape)\n",
    "        print(f\"Estimated intrinsic matrix:\\n{K}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Intrinsic estimation failed: {e}\")\n",
    "        K = np.array([[0.8*w, 0, w/2], [0, 0.8*w, h/2], [0, 0, 1]])\n",
    "        print(f\"Using fallback intrinsics:\\n{K}\")\n",
    "        F, _ = cv.findFundamentalMat(ptsL, ptsR, cv.USAC_MAGSAC, 1.0, 0.999, 50000)\n",
    "\n",
    "    # Evaluate epipolar error\n",
    "    if F is not None:\n",
    "        epipolar_error_mean, _ = compute_epipolar_error(ptsL, ptsR, F)\n",
    "        \n",
    "    # Estimate pose\n",
    "    E, mask = cv.findEssentialMat(ptsL, ptsR, K, method=cv.RANSAC, prob=0.999, threshold=0.5, maxIters=5000)\n",
    "    if E is None:\n",
    "        R = np.eye(3)\n",
    "        t = np.array([0, 0, 1])\n",
    "        mask = np.ones((len(ptsL), 1), dtype=np.uint8)\n",
    "    else:\n",
    "        _, R, t, mask_pose = cv.recoverPose(E, ptsL, ptsR, K, mask=mask)\n",
    "        mask = mask_pose.ravel().astype(bool)\n",
    "        print(f\"Recovered rotation:\\n{R}\\nTranslation:\\n{t}\")\n",
    "\n",
    "    ptsL = ptsL[mask]\n",
    "    ptsR = ptsR[mask]\n",
    "    \n",
    "    # Rectification\n",
    "    R1, R2, P1, P2, Q, _, _ = cv.stereoRectify(\n",
    "        K, None, K, None, (w, h), R, t, flags=cv.CALIB_ZERO_DISPARITY, alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Create rectification maps\n",
    "    mapL1, mapL2 = cv.initUndistortRectifyMap(K, None, R1, P1, (w, h), cv.CV_32FC1)\n",
    "    mapR1, mapR2 = cv.initUndistortRectifyMap(K, None, R2, P2, (w, h), cv.CV_32FC1)\n",
    "\n",
    "    # Rectify images\n",
    "    img_left_rect = cv.remap(img_left, mapL1, mapL2, cv.INTER_LANCZOS4)\n",
    "    img_right_rect = cv.remap(img_right, mapR1, mapR2, cv.INTER_LANCZOS4)\n",
    "    \n",
    "    # Rectify points\n",
    "    ptsL_rect = cv.undistortPoints(ptsL.reshape(-1,1,2), K, None, R=R1, P=P1).reshape(-1,2)\n",
    "    ptsR_rect = cv.undistortPoints(ptsR.reshape(-1,1,2), K, None, R=R2, P=P2).reshape(-1,2)\n",
    "    \n",
    "    # Epipolar line visualization\n",
    "    draw_epipolar_lines(img_left_rect, img_right_rect, ptsL_rect, ptsR_rect,\n",
    "                       \"output_uncalibrated/rectified_epipolar.jpg\")\n",
    "\n",
    "    # Evaluate vertical disparity\n",
    "    if len(ptsL_rect) > 0:\n",
    "        vertical_disparity = np.abs(ptsL_rect[:, 1] - ptsR_rect[:, 1])\n",
    "        mean_vertical_disp = np.mean(vertical_disparity)\n",
    "\n",
    "    # Triangulation\n",
    "    if len(ptsL) > 0:\n",
    "        P0 = K @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "        P1 = K @ np.hstack((R, t))\n",
    "        pts4d = cv.triangulatePoints(P0, P1, ptsL.T, ptsR.T)\n",
    "        points3d = (pts4d[:3] / pts4d[3]).T\n",
    "\n",
    "        # Filtering\n",
    "        valid_mask = fast_depth_filter(points3d)\n",
    "        points3d = points3d[valid_mask]\n",
    "        ptsL_valid = ptsL[valid_mask]\n",
    "        ptsR_valid = ptsR[valid_mask]\n",
    "\n",
    "    else:\n",
    "        points3d = np.zeros((0, 3))\n",
    "        ptsL_valid = np.zeros((0, 2))\n",
    "        ptsR_valid = np.zeros((0, 2))\n",
    "\n",
    "    # Reprojection Error Calculation\n",
    "    if len(points3d) > 0:\n",
    "        # Left camera reprojection\n",
    "        projected_left = (K @ points3d.T).T\n",
    "        projected_left = projected_left[:, :2] / projected_left[:, 2:]\n",
    "        repr_error_left = np.mean(np.linalg.norm(ptsL_valid - projected_left, axis=1))\n",
    "\n",
    "        # Right camera reprojection\n",
    "        points3d_right = (R @ points3d.T + t).T\n",
    "        projected_right = (K @ points3d_right.T).T\n",
    "        projected_right = projected_right[:, :2] / projected_right[:, 2:]\n",
    "        repr_error_right = np.mean(np.linalg.norm(ptsR_valid - projected_right, axis=1))\n",
    "        avg_reproj_error = (repr_error_left + repr_error_right) / 2\n",
    "    # Create colored point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points3d)\n",
    "    \n",
    "    if len(points3d) > 0:\n",
    "        colors = get_colors(img_left_color, ptsL_valid)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    # Point cloud cleaning\n",
    "    if len(points3d) > 50:\n",
    "        pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=50, std_ratio=1.5)\n",
    "        pcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "    \n",
    "    # Compute point cloud metrics\n",
    "    pc_metrics = compute_point_cloud_metrics(pcd)\n",
    "    print(\"\\n====== Reconstruction Quality Summary ======\")\n",
    "    print(f\"Matches used: {len(good)}\")\n",
    "    print(f\"Epipolar Geometry Error (Pre-Rectification): {epipolar_error_mean:.4f} px\")\n",
    "    print(f\"Vertical Disparity (Post-Rectification): {mean_vertical_disp:.4f} px\")\n",
    "    print(f\"Average Reprojection Error: {avg_reproj_error:.4f} px\")\n",
    "    print(f\"Point Cloud Size: {pc_metrics['num_points']}\")\n",
    "    print(f\"Point Cloud Density: {pc_metrics['mean_neighbor_distance']:.4f} m\")\n",
    "    print(f\"Depth Mean: {pc_metrics['depth_distribution']['mean']:.2f} m\")\n",
    "    print(f\"Depth Range: {pc_metrics['depth_distribution']['min']:.2f} – {pc_metrics['depth_distribution']['max']:.2f} m\")\n",
    "    print(\"============================================\")\n",
    "\n",
    "    # Save point cloud\n",
    "    o3d.io.write_point_cloud(\"output_uncalibrated/reconstruction.ply\", pcd)\n",
    "    print(\"Saved point cloud: output_uncalibrated/reconstruction.ply\")\n",
    "\n",
    "    print(\"Reconstruction complete. Results saved in output directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimized_3d_reconstruction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
